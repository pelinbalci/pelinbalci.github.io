---
layout: page
title: Academic Studies
permalink: /Academic Studies/
---

Articles that I've Read: 
- Attention Is All You Need, Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, 
  A. N., Kaiser, L., Polosukhin, I. [link](arXivpreprintarXiv:1706.03762,2017)


Posts
- [AI Poses Doomsday Risks—But That Doesn’t Mean We Shouldn’t Talk About Present Harms Too](https://time.com/6303127/ai-future-danger-present-harms/)

      Notes: 
      First, the public currently has little to no say over what models are built and how they are deployed.those most 
      affected by welfare systems have had little say in their automation. 
       
      Second, a strong auditing regime, where independent third-parties would scrutinize the practices and development 
      processes of AI labs, would help reduce risks overall. 

      Third, we should require meaningful human oversight of critical AI decisions, and avoid very-high-risk use cases such 
      as lethal autonomous weapons. 

      Fourth, we should rebalance the  funding going into AIs and urge companies to spend less on making them smarter 
      while increasing funding into making them safer, more transparent, and studying their social impacts. "



