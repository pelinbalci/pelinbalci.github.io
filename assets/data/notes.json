{
  "generated_at": "2025-11-25T19:54:51.443916Z",
  "nodes": [
    {
      "id": "optimization",
      "name": "Optimization Algorithms in Neural Networks",
      "category": "deep-learning",
      "tags": [
        "deep learning",
        "backpropagation",
        "cs231n"
      ],
      "date": "2020-10-14",
      "description": "Optimization Algorithms in Neural Network will be explained",
      "related": [
        "dl"
      ],
      "file": "2020-10-14-optimization_algorithms.md",
      "html": "<p>In this post, Optimization Algorithms in Neural Network will be explained. Thanks to Stanford University, the lecture \nvideos of cs231n can be found in YouTube and all materials are freely available (see the references). </p>\n<h1>First Order Optimization Algorithms</h1>\n<ul>\n<li>SGD</li>\n<li>SGD with Momentum</li>\n<li>SGD with Nesterov Momentum</li>\n<li>AdaGrad</li>\n<li>RMSProp</li>\n<li>Adam</li>\n</ul>\n<h2>SGD</h2>\n<pre><code>w = w - learningrate * gradient\n</code></pre>\n<ul>\n<li>Vanilla update. </li>\n<li>The simplest form of update is to change the parameters along the negative gradient direction </li>\n<li>Since the gradient indicates the direction of increase, but we usually wish to minimize a loss function</li>\n</ul>\n<h2>SGD with Momentum</h2>\n<pre><code>velocity = 0\nvelocity = momentum * velocity - learningrate * gradient\nw = w + velocity\n</code></pre>\n<ul>\n<li>With Momentum update, the parameter vector will build up velocity in any direction that has consistent gradient.</li>\n</ul>\n<div class=\"fig figcenter fighighlight\">\n  <img src=\"/assets/image_assets/optimization_images/sgd_vs_momentum.png\" width=\"75%\">\n  <div class=\"figcaption\">Figure 1: SGD vs SGD with Momentum</div>\n</div>\n\n<h2>SGD with Nesterov Momentum</h2>\n<pre><code>old_velocity = velocity\nvelocity = momentum * velocity - learningrate * gradient\nw = w + (-momentum) * old_velocity + (1- (-momentum)) * velocity\n</code></pre>\n<ul>\n<li>https://arxiv.org/pdf/1212.0901v2.pdf : ADVANCES IN OPTIMIZING RECURRENT NETWORKS</li>\n<li>http://www.cs.utoronto.ca/~ilya/pubs/ilya_sutskever_phd_thesis.pdf : RNN </li>\n</ul>\n<h2>AdaGrad</h2>\n<p>Ref: https://jmlr.org/papers/volume12/duchi11a/duchi11a.pdf (-)\nRef: https://arxiv.org/pdf/1212.5701.pdf *</p>\n<pre><code>gradient_squared = 0 \ngradient_squared += gradient**2\nw += - learning_rate * gradient / (np.sqrt(gradient_squared) + eps)\n</code></pre>\n<p><strong>Pros:</strong> *</p>\n<p>While there is the hand tuned global learning rate, each dimension has its own dynamic rate. </p>\n<p>Since this dynamic rate grows with the inverse of the gradient magnitudes:\n    - large gradients have smaller learning rates\n    - small gradients have large learning rates. </p>\n<p>This is very beneficial for training deep neural networks since the scale of the gradients in each layer is often \ndifferent by several orders of magnitude, so the optimal learning rate should take that into account. </p>\n<p>Accumulation of gradient in the denominator has the same effects as annealing, reducing the learning rate over time. </p>\n<p><strong>Cons:</strong> * </p>\n<ul>\n<li>This method can be sensitive to initial conditions of the parameters and the corresponding gradients. </li>\n<li>If the initial gradients are large, the learning rates will be low for the remainder of training. </li>\n<li>This can be combatted by increasing the global learning rate, making the ADAGRAD method sensitive to the choice of \nlearning rate. </li>\n<li>Due to the continual accumulation of squared gradients in the denominator, the learning rate will continue to decrease \nthroughout training, eventually decreasing to zero and stopping training completely.</li>\n<li>Another exp:  A downside of Adagrad is that in case of Deep Learning, the monotonic learning rate usually proves too \naggressive and stops learning too early. **</li>\n</ul>\n<h2>RMS Prop</h2>\n<pre><code>gradient_squared = 0 \ngradient_squared = decay_rate * gradient_squared + (1 - decay_rate) * gradient**2\nw += - learning_rate * gradient / (np.sqrt(gradient_squared) + eps)\n</code></pre>\n<ul>\n<li>The RMSProp update adjusts the Adagrad method in a very simple way in an attempt to reduce its aggressive, monotonically \ndecreasing learning rate. </li>\n<li>In particular, it uses a moving average of squared gradients.</li>\n<li>\n<p>decay_rate is a hyperparameter and typical values are [0.9, 0.99, 0.999]. </p>\n</li>\n<li>\n<p>Notice that the w+= update is identical to Adagrad.</p>\n</li>\n<li>But the gradient_squared variable is a \u201cleaky\u201d. (has decay rate)</li>\n<li>Hence, RMSProp still modulates the learning rate of each weight based on the magnitudes of its gradients. \nIt has a beneficial equalizing effect.</li>\n<li>But unlike Adagrad, the updates do not get monotonically smaller.</li>\n</ul>\n<h1>Adam</h1>\n<p>Ref: https://arxiv.org/pdf/1412.6980.pdf</p>\n<pre><code># t is your iteration counter going from 1 to infinity\nfirst_moment, second_moment = 0, 0\nfor t in range(iterations):\n    first_moment = beta1 * first_moment + (1-beta1) * gradient\n    first_unbias = first_moment / (1-beta1**t)\n\n    second_moment = beta2 * second_moment + (1-beta2)*(gradient**2)\n    second_unbias = second_moment / (1-beta2**t)\n\n    w += - learning_rate * first_unbias / (np.sqrt(second_unbias) + eps)\n</code></pre>\n<p>The method computes individual adaptive learning rates for different parameters from estimates of first and second \nmoments of the gradients; the name Adam is derived from adaptive moment estimation.</p>\n<p>Without bias: </p>\n<p>At very first time step, second moment is zero. After one update teh second moment will still close to zero. When we\ndivide by second moment, we make a very large step at the beginning.  But this big step is not related with the geometry of the \nloss function, it is the nature of the formula. </p>\n<p>Bias correction term help to aviod the very large step at the beginning. </p>\n<p>You can start with these parameters:</p>\n<pre><code>beta1 = 0.9\nbeta2 = 0.999\nlr = 1e-3 or 1e-5\n</code></pre>\n<p>RMSProp with momentum generates its parameter updates using a momentum on the rescaled gradient, whereas Adam updates are\ndirectly estimated using a running average of first and second moment of the gradient. </p>\n<p>RMSProp also lacks a bias-correction term; this matters most in case of a value of beta2 close to 1 (required in\ncase of sparse gradients), since in that case not correcting the bias leads to very large stepsizes and\noften divergence. </p>\n<p>Different Models comparison: {'sgd': 5e-3, 'sgd_momentum':  5e-3, 'rmsprop': 1e-4, 'adam': 1e-3}</p>\n<div class=\"fig figcenter fighighlight\">\n  <img src=\"/assets/image_assets/optimization_images/different_models.png\" width=\"75%\">\n  <div class=\"figcaption\">Figure 2: Different models</div>\n</div>\n\n<p>Different Models comparison: {'sgd': 1e-3, 'sgd_momentum':  1e-3, 'rmsprop': 1e-3, 'adam': 1e-3}</p>\n<div class=\"fig figcenter fighighlight\">\n  <img src=\"/assets/image_assets/optimization_images/different_models_same_lr.png\" width=\"75%\">\n  <div class=\"figcaption\">Figure 3: Different models with the same learning rate</div>\n</div>\n\n<h2>Change LR</h2>\n<p>you can change learning rate during the training:</p>\n<ul>\n<li>Step Decay</li>\n<li>Exponential Decay</li>\n<li>1/t decay</li>\n</ul>\n<p>Start with no decay. Select the best learning rate. Check the loss plot and decide where you need decay. </p>\n<h4>'sgd' :</h4>\n<div class=\"fig figcenter fighighlight\">\n  <img src=\"/assets/image_assets/optimization_images/sgd_lr.png\" width=\"75%\">\n  <div class=\"figcaption\">Figure 4: SGD, learning rates: [1e-4, 5e-3, 3e-3, 1e-3, 1e-2]</div>\n</div>\n\n<h4>'sgd_momentum':</h4>\n<div class=\"fig figcenter fighighlight\">\n  <img src=\"/assets/image_assets/optimization_images/sgd_moment_lr.png\" width=\"75%\">\n  <div class=\"figcaption\">Figure 5: SGD with Momentum, learning rates: [1e-4, 5e-3, 3e-3, 1e-3, 1e-2]</div>\n</div>\n\n<h4>'rmsprop':</h4>\n<div class=\"fig figcenter fighighlight\">\n  <img src=\"/assets/image_assets/optimization_images/rms_lr.png\" width=\"75%\">\n  <div class=\"figcaption\">Figure 6: RMSProp, learning rates: [1e-4, 5e-4, 5e-3, 1e-3, 1e-2]</div>\n</div>\n\n<p>RMS Prop needs smaller lr: [1e-5, 5e-5, 5e-4, 1e-4]\n- running with  5e-05: (Epoch 5 / 5) train acc: 0.591000; val_acc: 0.359000\n- running with  0.0001: (Epoch 5 / 5) train acc: 0.557000; val_acc: 0.376000</p>\n<div class=\"fig figcenter fighighlight\">\n  <img src=\"/assets/image_assets/optimization_images/rms_lr_smaller.png\" width=\"75%\">\n  <div class=\"figcaption\">RMSProp, smaller learning rates</div>\n</div>\n\n<h4>'adam':</h4>\n<div class=\"fig figcenter fighighlight\">\n  <img src=\"/assets/image_assets/optimization_images/adam_lr.png\" width=\"75%\">\n  <div class=\"figcaption\">Figure 7: Adam, learning rates: [1e-4, 5e-4, 5e-3, 1e-3, 1e-2]</div>\n</div>\n\n<h2>Model Ensembles</h2>\n<p>Ref: https://www.youtube.com/watch?v=EK61htlw8hY&amp;ab_channel=TTIC</p>\n<p>One disadvantage of model ensembles is that they take longer to evaluate on test example. \nAn interested reader may find the recent work from Geoff Hinton on \u201cDark Knowledge\u201d inspiring, where the idea is to \n\u201cdistill\u201d a good ensemble back to a single model by incorporating the ensemble log likelihoods into a modified objective.</p>\n<p>Ref: https://www.youtube.com/watch?v=_JB0AO7QxSA&amp;list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv&amp;index=7&amp;ab_channel=StanfordUniversitySchoolofEngineering</p>\n<ol>\n<li>Train multiple independent models </li>\n<li>At test time average their results </li>\n</ol>\n<h1>Second Order Optimization Algorithms</h1>\n<ul>\n<li>https://arxiv.org/pdf/1311.2115.pdf (Quasi Newton)</li>\n<li>https://research.google/pubs/pub40565/ (Large Scale Distributed Deep Networks)</li>\n<li>https://en.wikipedia.org/wiki/Limited-memory_BFGS (LBFGS)</li>\n</ul>\n<h1>References</h1>\n<ul>\n<li>https://www.youtube.com/watch?v=_JB0AO7QxSA&amp;list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv&amp;index=7&amp;ab_channel=StanfordUniversitySchoolofEngineering</li>\n<li>https://cs231n.github.io/</li>\n</ul>\n<h1>Key Words</h1>\n<p>SGD, Momentum, Learning Rates, RMSProp, ADam, Optimization, Neural Networks</p>",
      "excerpt": "In this post, Optimization Algorithms in Neural Network will be explained. Thanks to Stanford University, the lecture videos of cs231n can be found in YouTube and all materials are freely available (s..."
    },
    {
      "id": "kmeans",
      "name": "K-means with Numpy",
      "category": "machine-learning",
      "tags": [
        "machine learning",
        "unsupervised learning",
        "numpy",
        "medium"
      ],
      "date": "2023-03-07",
      "description": "Explanation of K-means algorithm with Numpy",
      "related": [
        "ml"
      ],
      "file": "2023-03-07-K_means_with_numpy.md",
      "html": "<p>In this post, I will explain the K-means algorithm via Numpy. Continue reading by clicking <a href=\"https://medium.com/@balci.pelin/k-means-with-numpy-3c207398c4d4\">here</a></p>",
      "excerpt": "In this post, I will explain the K-means algorithm via Numpy. Continue reading by clicking [here](https://medium.com/@balci.pelin/k-means-with-numpy-3c207398c4d4)"
    },
    {
      "id": "crossentropy",
      "name": "Cross-Entropy Loss",
      "category": "deep-learning",
      "tags": [
        "deep learning",
        "dl",
        "loss",
        "cross entropy",
        "medium"
      ],
      "date": "2023-03-11",
      "description": "Simple example for cross entropy loss",
      "related": [
        "dl"
      ],
      "file": "2023-03-11-Cross_Entropy_Loss.md",
      "html": "<p><a href=\"https://medium.com/@balci.pelin/cross-entropy-loss-5568329c9d3\">Read the full version on Medium</a> I will explain the cross-entropy loss with a very simple example.</p>",
      "excerpt": "[Read the full version on Medium](https://medium.com/@balci.pelin/cross-entropy-loss-5568329c9d3) I will explain the cross-entropy loss with a very simple example."
    },
    {
      "id": "llm",
      "name": "LLM Introduction",
      "category": "genai",
      "tags": [
        "llm",
        "medium"
      ],
      "date": "2023-07-17",
      "description": "LLM Introduction",
      "related": [],
      "file": "2023-07-17-LLM_Intro.md",
      "html": "<p><a href=\"https://medium.com/@balci.pelin/llm-introduction-7ededa51b78b\">Read the full version on Medium</a>If you think that, \nnow that ChatGPT handles everything and you are late to learn it, this article is for you:)</p>",
      "excerpt": "[Read the full version on Medium](https://medium.com/@balci.pelin/llm-introduction-7ededa51b78b)If you think that, now that ChatGPT handles everything and you are late to learn it, this article is for..."
    },
    {
      "id": "configuration",
      "name": "LLM Configurations",
      "category": "genai",
      "tags": [
        "llm",
        "configuration",
        "top_k",
        "medium",
        "video"
      ],
      "date": "2023-07-22",
      "description": "A brief introduction to LLM configurations",
      "related": [
        "llm",
        "temperature"
      ],
      "file": "2023-07-22-LLM_Configurations.md",
      "html": "<p><a href=\"https://medium.com/@balci.pelin/llm-inference-222c8e8a6ba7\">Read the full version on Medium</a> What are the configuration parameters that can influence the model\u2019s output during \ninference? Click here to watch the video on <a href=\"https://youtu.be/KbUPOJ8Fmzs\">YouTube</a></p>",
      "excerpt": "[Read the full version on Medium](https://medium.com/@balci.pelin/llm-inference-222c8e8a6ba7) What are the configuration parameters that can influence the model\u2019s output during inference? Click here t..."
    },
    {
      "id": "fewshot",
      "name": "LLM FewShot Learning",
      "category": "genai",
      "tags": [
        "llm",
        "fewshot",
        "zeroshot",
        "prompt",
        "medium",
        "video"
      ],
      "date": "2023-07-24",
      "description": "Explanation of Zero-Shot One-Shot and Few Shot on code",
      "related": [
        "llm"
      ],
      "file": "2023-07-24-LLM_FewShot_Learning.md",
      "html": "<p><a href=\"https://medium.com/@balci.pelin/llm-few-shot-learning-d7df1d2c4446\">Read the full version on Medium</a> Explanation of Zero-Shot One-Shot and Few Shot on code.<br />\nClick here to watch the video on <a href=\"https://youtu.be/byRgzRCRSvw\">YouTube</a></p>",
      "excerpt": "[Read the full version on Medium](https://medium.com/@balci.pelin/llm-few-shot-learning-d7df1d2c4446) Explanation of Zero-Shot One-Shot and Few Shot on code. Click here to watch the video on [YouTube]..."
    },
    {
      "id": "evaluation",
      "name": "LLM Evaluation",
      "category": "genai",
      "tags": [
        "evaluation",
        "llm",
        "medium"
      ],
      "date": "2023-08-01",
      "description": "A practical guide to measure the model performance",
      "related": [
        "llm"
      ],
      "file": "2023-08-01-LLM_Evaluation.md",
      "html": "<p><a href=\"https://medium.com/@balci.pelin/llm-evaluation-6b63b3cfd48b\">TL;DR? Read the full version on Medium</a> This article is a practical guide to measure the model performance and to make sure that the model gives good results \nafter fine-tuning.</p>",
      "excerpt": "[TL;DR? Read the full version on Medium](https://medium.com/@balci.pelin/llm-evaluation-6b63b3cfd48b) This article is a practical guide to measure the model performance and to make sure that the model..."
    },
    {
      "id": "ner",
      "name": "NER",
      "category": "deep-learning",
      "tags": [
        "deep learning",
        "dl",
        "ner",
        "from scratch",
        "medium"
      ],
      "date": "2023-08-16",
      "description": "Build your NER data from scratch and learn the details of the NER model",
      "related": [
        "dl"
      ],
      "file": "2023-08-16-NER.md",
      "html": "<p><a href=\"https://medium.com/@balci.pelin/ner-8eb9694ccad3\">Read the full version on Medium</a> Build your NER data from scratch and learn the details of the NER model.</p>",
      "excerpt": "[Read the full version on Medium](https://medium.com/@balci.pelin/ner-8eb9694ccad3) Build your NER data from scratch and learn the details of the NER model."
    },
    {
      "id": "finetuning",
      "name": "LLM Finetuning",
      "category": "genai",
      "tags": [
        "evaluation",
        "llm",
        "medium",
        "finetuning"
      ],
      "date": "2023-09-17",
      "description": "A practical guide to measure the model performance",
      "related": [
        "llm",
        "evaluation"
      ],
      "file": "2023-09-17-LLM_Finetuning.md",
      "html": "<p><a href=\"https://medium.com/@balci.pelin/llm-finetuning-410e8a2738ef\">Read the full version on Medium</a> Finetuning doesn\u2019t have \nto be a mystery anymore! In this article, I\u2019ve created a simple notebook that breaks down the \nprocess in an easy-to-understand way.</p>",
      "excerpt": "[Read the full version on Medium](https://medium.com/@balci.pelin/llm-finetuning-410e8a2738ef) Finetuning doesn\u2019t have to be a mystery anymore! In this article, I\u2019ve created a simple notebook that bre..."
    },
    {
      "id": "faq",
      "name": "LLM FAQ",
      "category": "genai",
      "tags": [
        "evaluation",
        "llm",
        "prompt",
        "finetuning",
        "medium"
      ],
      "date": "2023-09-18",
      "description": "Q&A for LLM",
      "related": [
        "llm"
      ],
      "file": "2023-09-18-LLM_Q_A.md",
      "html": "<p><a href=\"https://medium.com/@balci.pelin/llm-q-a-4c98031d9ea3\">Read the full version on Medium</a> If you\u2019ve been curious about LLMs and still have questions, this article \nis just for you. Get ready to dive deep into the world of language models!</p>",
      "excerpt": "[Read the full version on Medium](https://medium.com/@balci.pelin/llm-q-a-4c98031d9ea3) If you\u2019ve been curious about LLMs and still have questions, this article is just for you. Get ready to dive deep..."
    },
    {
      "id": "temperature",
      "name": "Temperature",
      "category": "genai",
      "tags": [
        "temperature",
        "llm",
        "video"
      ],
      "date": "2025-11-08",
      "description": "A brief description of temperature parameter",
      "related": [
        "llm",
        "configuration"
      ],
      "file": "2023-10-16-Temperature_parameter.md",
      "html": "<h1>Temperature</h1>\n<p><strong>Temperature</strong> is a parameter which is injected into the <strong>softmax function</strong>, enabling the users to manipulate the \noutput probabilities. It helps us to control the <strong>creativeness</strong> of a Large Language Model.</p>\n<p>The range of the temperature parameter is defined as 0 and 1 in OpenAI documentation. In the context of Cohere, \ntemperature values fall within the range of 0 to 5. <em>See the references below.</em></p>\n<hr />\n<p>This is the original softmax function: </p>\n<div class=\"fig figcenter fighighlight\">\n  <img src=\"/assets/image_assets/temperature_images/softmax.PNG\" width=\"50%\">\n  <div class=\"figcaption\"> </div>\n</div>\n\n<p>When we add Temperature parameter:</p>\n<div class=\"fig figcenter fighighlight\">\n  <img src=\"/assets/image_assets/temperature_images/softmax_temp.PNG\" width=\"50%\">\n  <div class=\"figcaption\"> </div>\n</div>\n\n<p>Remember that zj is the output of the neural network: it is a floating number. If you want to learn more about \nsoftmax function, read <a href=\"https://github.com/pelinbalci/Intro_Deep_Learning/blob/master/Intro_NN/notes/1_Perceptron_math.md#multiclass-classification--softmax:~:text=Multiclass%20Classification%20%26%20Softmax\">here</a>.</p>\n<hr />\n<ul>\n<li>As Temperature approaches 0, the output probabilities become more \"sharp\". One of the probability will be close to 1.</li>\n<li>As Temperature increases, the output probabilities become more \"flat\" or \"uniform\", reducing the difference between the probabilities of different elements.</li>\n</ul>\n<p>If we want repetitive answers, and no creativity at all, we can decrease the Temperature. If we want more creative answers, we can increase it.</p>\n<hr />\n<h1>Example</h1>\n<p>Let's imagine that our corpus has only 5 words: [\"donut\", \"cake\", \"apple\", \"juice\", \"book\"]</p>\n<p>The prediction of next token of given sentence: \"At the table, there is a delicious\" will be one of the words in the corpus. </p>\n<p>These are the original results: </p>\n<div class=\"fig figcenter fighighlight\">\n  <img src=\"/assets/image_assets/temperature_images/softmax_df.PNG\" width=\"50%\">\n  <div class=\"figcaption\"> </div>\n</div>\n\n<p>You can try different temperature values to see how the output changes.</p>\n<div>\n<iframe \n    src=\"https://www.pelinbalci.com/assets/components/temperature_slider.html\" \n    width=\"100%\" \n    height=\"600\" \n    style=\"border:none;\"\n></iframe>\n</div>\n\n<p>Listen my YouTube Vide from <a href=\"https://youtu.be/KbUPOJ8Fmzs\">here</a></p>\n<p>Happy Learning! :)</p>\n<h1>References</h1>\n<ul>\n<li>[1] https://platform.openai.com/docs/api-reference/audio/createTranscription#audio/createTranscription-temperature</li>\n<li>[2] https://txt.cohere.com/llm-parameters-best-outputs-language-ai/</li>\n<li>[3] https://peterchng.com/blog/2023/05/02/token-selection-strategies-top-k-top-p-and-temperature/</li>\n</ul>",
      "excerpt": "# Temperature **Temperature** is a parameter which is injected into the **softmax function**, enabling the users to manipulate the output probabilities. It helps us to control the **creativeness** of ..."
    },
    {
      "id": "quantization",
      "name": "Quantization 1",
      "category": "deep-learning",
      "tags": [
        "deep learning",
        "dl",
        "quantization",
        "medium"
      ],
      "date": "2024-05-05",
      "description": "Unlocking the Power of Quantization: From Float32 to Int8",
      "related": [
        "finetuning",
        "dl"
      ],
      "file": "2024-05-05-Quantization_1.md",
      "html": "<p><a href=\"https://medium.com/@balci.pelin/quantization-1-d05e5a61e0af\">Read the full version on Medium</a> </p>\n<p>Why do we need quantization?\n* Shrink models to a small size.\n* DL architectures are bigger and bigger.\n* A model can have 70 billion parameters.\n* NVIDIA T4 GPUs have 16 GB RAM.\n* Running models are still a challenge.\n* The aim is to get a smaller model.</p>",
      "excerpt": "[Read the full version on Medium](https://medium.com/@balci.pelin/quantization-1-d05e5a61e0af) Why do we need quantization? * Shrink models to a small size. * DL architectures are bigger and bigger. *..."
    },
    {
      "id": "quantization_2",
      "name": "Quantization 2",
      "category": "deep-learning",
      "tags": [
        "deep learning",
        "dl",
        "quantization",
        "medium"
      ],
      "date": "2024-05-06",
      "description": "Mastering Post-training Quantization: A Guide with PyTorch and TensorFlow",
      "related": [
        "finetuning",
        "quantization",
        "dl"
      ],
      "file": "2024-05-06-Quantization_2.md",
      "html": "<p><a href=\"https://medium.com/@balci.pelin/quantization-2-7398a0ce7584\">Read the full version on Medium</a> Understanding quantization can feel like learning two different languages when comparing TensorFlow and PyTorch. In this \npost, I\u2019ll guide you through the differences and similarities, providing clear explanations along the way. You can find \nall the code references and notes in the provided <a href=\"https://github.com/pelinbalci/LLM_Notebooks/blob/main/Quantization.ipynb\">notebook</a></p>",
      "excerpt": "[Read the full version on Medium](https://medium.com/@balci.pelin/quantization-2-7398a0ce7584) Understanding quantization can feel like learning two different languages when comparing TensorFlow and P..."
    },
    {
      "id": "poster",
      "name": "ECDP '24 Poster",
      "category": "conference",
      "tags": [
        "poster",
        "ner",
        "pathology"
      ],
      "date": "2024-06-05",
      "description": "Poster in 20th European Congress on Digital Pathology 2024",
      "related": [],
      "file": "2024-06-05-ecdp_24_poster.md",
      "html": "<p>I'm excited to share that <a href=\"https://lnkd.in/dJ2WKKRF\">our poster</a> is in 20th European Congress on Digital Pathology 2024 | \nECDP2024! \u2728</p>\n<p>First and foremost, I owe my heartfelt thanks to hashtag#MemorialPathology Memorial Healthcare Group and Dr. Serdar \nBalc\u0131 for involving me in this project and for all their invaluable support and assistance throughout this journey.</p>\n<p>Our study highlights the importance of extracting information from pathology reports using Named Entity Recognition \n(NER). We conducted extensive tests utilizing various models (BERT Models and GPT) to ensure robust results.</p>\n<p>You can try our GPTs: \"PathText\" <a href=\"https://lnkd.in/dzyC6PJm\">here</a>. \u2728 And you may find a <a href=\"https://www.linkedin.com/posts/activity-7204810402281512960-_w5D?utm_source=share&amp;utm_medium=member_desktop\">video</a> \nabout that. It is currently in the beta testing phase, and we aim to develop it into a more comprehensive product.</p>",
      "excerpt": "I'm excited to share that [our poster](https://lnkd.in/dJ2WKKRF) is in 20th European Congress on Digital Pathology 2024 | ECDP2024! \u2728 First and foremost, I owe my heartfelt thanks to hashtag#MemorialP..."
    },
    {
      "id": "devfest",
      "name": "GDG Devfest'24 Notes",
      "category": "conference",
      "tags": [
        "llmops",
        "google",
        "devfest"
      ],
      "date": "2024-11-09",
      "description": "I've joined GDG devfest'24 event.",
      "related": [],
      "file": "2024-11-09-devfest_notes.md",
      "html": "<p>I've joined GDG devfest'24 event yesterday. There were remarkable speakers. I would like to add my notes.\nYou may find the link of the conference <a href=\"https://devfest.istanbul/\">here</a></p>\n<h2>Devops MLOps LLMOps</h2>\n<p>I've combined the presentation notes and get a little help from chatgpt to prepare this chart. It shows the differences\nbetween Devops, MLOps and LLMOps Practices. The presentations are: </p>\n<ul>\n<li>From Devops to MLOps fro Majd Jamaah - Beyond Limits, GDE</li>\n<li>From Ideation to production: GENAI Application  Development and LLMOps from Emrah Mete - Microsoft</li>\n</ul>\n<div class=\"fig figcenter fighighlight\">\n  <img src=\"/assets/image_assets/devops_images/devops_mlops_llmops.png\" width=\"50%\">\n  <div class=\"figcaption\"> </div>\n</div>\n\n<h2>Useful Links</h2>\n<p>Google Trainings: https://cloud.google.com/learn/training/machinelearning-ai</p>\n<p>Alpha Proteo: https://deepmind.google/discover/blog/alphaproteo-generates-novel-proteins-for-biology-and-health-research/</p>\n<p>Nobel Prize: https://deepmind.google/discover/blog/demis-hassabis-john-jumper-awarded-nobel-prize-in-chemistry/</p>\n<p>Gemini Long Context Kaggle Competition: https://www.kaggle.com/competitions/gemini-long-context</p>\n<p>Agents:\n- https://haystack.deepset.ai/cookbook/web_enhanced_self_reflecting_agent?utm_campaign=developer-relations&amp;utm_source=devfest-ist-2024&amp;utm_medium=presentation\n- https://github.com/daronyondem/codesamples/tree/main/AutoGen\n- https://lilianweng.github.io/posts/2023-06-23-agent/</p>\n<p>Run Language Models: \n- https://ollama.com/\n- https://lmstudio.ai/\n- https://www.microsoft.com/en-us/research/blog/introducing-autogen-studio-a-low-code-interface-for-building-multi-agent-workflows/</p>",
      "excerpt": "I've joined GDG devfest'24 event yesterday. There were remarkable speakers. I would like to add my notes. You may find the link of the conference [here](https://devfest.istanbul/) ## Devops MLOps LLMO..."
    },
    {
      "id": "reinvent",
      "name": "AWS re:Invent Recap 1",
      "category": "conference",
      "tags": [
        "aws",
        "reinvent",
        "medium"
      ],
      "date": "2024-06-05",
      "description": "re:Invent notes",
      "related": [
        "reinvent_2"
      ],
      "file": "2024-12-17-aws-reinvent.md",
      "html": "<p><a href=\"https://medium.com/@balci.pelin/aws-re-invent-2024-notes-part1-f185ed9b326b\">TL;DR? Read the full version on Medium</a> \nThis year, I was privileged to join the AWS re: Invent in Las Vegas! It was a wonderful week, I met incredible people \nfrom around the world, exchanging ideas, and learning from their unique experiences. I\u2019ve decided to write and share my notes :)</p>",
      "excerpt": "[TL;DR? Read the full version on Medium](https://medium.com/@balci.pelin/aws-re-invent-2024-notes-part1-f185ed9b326b) This year, I was privileged to join the AWS re: Invent in Las Vegas! It was a wond..."
    },
    {
      "id": "reinvent_2",
      "name": "AWS re:Invent Recap 2",
      "category": "conference",
      "tags": [
        "aws",
        "reinvent",
        "medium"
      ],
      "date": "2024-06-05",
      "description": "re:Invent notes",
      "related": [
        "reinvent"
      ],
      "file": "2024-12-18-aws-reinvent-2.md",
      "html": "<p><a href=\"https://medium.com/@balci.pelin/aws-re-invent-2024-notes-part2-5318a2295bf9\">TL;DR? Read the full version on Medium</a> \nWelcome to the second part of my AWS re: Invent series! In this post, I\u2019ll be diving into some of the exciting announcements and sharing insights from the sessions I attended.</p>",
      "excerpt": "[TL;DR? Read the full version on Medium](https://medium.com/@balci.pelin/aws-re-invent-2024-notes-part2-5318a2295bf9) Welcome to the second part of my AWS re: Invent series! In this post, I\u2019ll be divi..."
    },
    {
      "id": "langchain_tools",
      "name": "Langchain Tools",
      "category": "genai",
      "tags": [
        "agents",
        "llm"
      ],
      "date": "2025-11-25",
      "description": "How LangChain calls the custom functions and how to leverage Tavily Search for internet searching.",
      "related": [
        "agentic-architecture"
      ],
      "file": "2025-01-18-LangChain_Tools.md",
      "html": "<p><a href=\"https://medium.com/@balci.pelin/getting-started-with-langchain-tools-3beec9e1fb95\">Read the full version on Medium</a> \nAre you curious about AI agents and ready to build them from scratch? This post will be a great start for you. I will \nshow you how LangChain calls the custom functions and how to leverage Tavily Search for internet searching. In future \nposts, we will dive into how these constructs fit into the agentic architecture. Stay tuned to learn more about AI agents!\u2728\ud83c\udf89</p>",
      "excerpt": "[Read the full version on Medium](https://medium.com/@balci.pelin/getting-started-with-langchain-tools-3beec9e1fb95) Are you curious about AI agents and ready to build them from scratch? This post wil..."
    },
    {
      "id": "agentic-architecture",
      "name": "Introduction to Agentic Architecture",
      "category": "genai",
      "tags": [
        "agents",
        "LLM",
        "autonomous systems",
        "AI architecture"
      ],
      "date": "2025-11-25",
      "description": "An overview of agentic AI systems, frameworks, and protocols that enable autonomous LLM-powered agents",
      "related": [
        "llm"
      ],
      "file": "agentic_architecture.md",
      "html": "<h1>Introduction to Agentic Architecture</h1>\n<p><strong>This article is generated by Claude Opus 4.5</strong></p>\n<h2>Overview</h2>\n<p>Agentic architecture represents a paradigm shift in how we build AI systems. Instead of simple prompt-response interactions, agentic systems can plan, reason, use tools, and execute multi-step tasks autonomously. These systems transform Large Language Models (LLMs) from passive responders into active problem-solvers.</p>\n<h2>What Makes an AI System \"Agentic\"?</h2>\n<p>An agentic system exhibits several key characteristics that distinguish it from traditional LLM applications:</p>\n<ul>\n<li><strong>Autonomy</strong>: The ability to make decisions and take actions without constant human intervention</li>\n<li><strong>Tool Use</strong>: Integration with external tools, APIs, and data sources to accomplish tasks</li>\n<li><strong>Planning</strong>: Breaking down complex goals into manageable steps</li>\n<li><strong>Memory</strong>: Maintaining context across interactions and learning from past experiences</li>\n<li><strong>Reflection</strong>: Self-evaluation and course correction when things go wrong</li>\n</ul>\n<h2>The Agent Loop</h2>\n<p>At its core, most agentic systems follow a similar pattern:</p>\n<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                                         \u2502\n\u2502   User Goal/Task                        \u2502\n\u2502         \u2502                               \u2502\n\u2502         \u25bc                               \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                         \u2502\n\u2502   \u2502  Observe  \u2502 \u25c4\u2500\u2500 Environment State   \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518                         \u2502\n\u2502         \u2502                               \u2502\n\u2502         \u25bc                               \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                         \u2502\n\u2502   \u2502   Think   \u2502 \u25c4\u2500\u2500 LLM Reasoning       \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518                         \u2502\n\u2502         \u2502                               \u2502\n\u2502         \u25bc                               \u2502\n\u2502   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510                         \u2502\n\u2502   \u2502    Act    \u2502 \u2500\u2500\u25ba Tool Execution      \u2502\n\u2502   \u2514\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2518                         \u2502\n\u2502         \u2502                               \u2502\n\u2502         \u25bc                               \u2502\n\u2502   Goal Achieved? \u2500\u2500No\u2500\u2500\u25ba  Loop Back     \u2502\n\u2502         \u2502                               \u2502\n\u2502        Yes                              \u2502\n\u2502         \u2502                               \u2502\n\u2502         \u25bc                               \u2502\n\u2502   Return Result                         \u2502\n\u2502                                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>\n<p>This \"observe-think-act\" loop allows agents to iteratively work toward goals, adapting their approach based on feedback from each action.</p>\n<h2>Key Concepts in Agentic Systems</h2>\n<h3>Tools and Function Calling</h3>\n<p>Tools extend an agent's capabilities beyond text generation. Modern LLMs support \"function calling\" where the model can request to execute specific functions with structured parameters:</p>\n<pre><code class=\"language-python\"># Example: Defining a tool for an agent\ntools = [\n    {\n        &quot;name&quot;: &quot;search_database&quot;,\n        &quot;description&quot;: &quot;Search the product database for items&quot;,\n        &quot;parameters&quot;: {\n            &quot;type&quot;: &quot;object&quot;,\n            &quot;properties&quot;: {\n                &quot;query&quot;: {&quot;type&quot;: &quot;string&quot;, &quot;description&quot;: &quot;Search query&quot;},\n                &quot;limit&quot;: {&quot;type&quot;: &quot;integer&quot;, &quot;description&quot;: &quot;Max results&quot;}\n            }\n        }\n    }\n]\n</code></pre>\n<h3>Memory Systems</h3>\n<p>Agents need memory to maintain coherence across long interactions:</p>\n<ul>\n<li><strong>Short-term memory</strong>: Current conversation context</li>\n<li><strong>Long-term memory</strong>: Persistent storage of facts, preferences, and past interactions</li>\n<li><strong>Episodic memory</strong>: Recollection of specific past events or tasks</li>\n<li><strong>Semantic memory</strong>: General knowledge and learned concepts</li>\n</ul>\n<h3>Planning Strategies</h3>\n<p>Different approaches to breaking down complex tasks:</p>\n<ul>\n<li><strong>ReAct (Reasoning + Acting)</strong>: Interleave reasoning traces with actions</li>\n<li><strong>Chain of Thought</strong>: Step-by-step reasoning before acting</li>\n<li><strong>Tree of Thoughts</strong>: Explore multiple reasoning paths</li>\n<li><strong>Plan-and-Execute</strong>: Create a full plan first, then execute</li>\n</ul>\n<h2>The Agentic Ecosystem</h2>\n<p>The field is rapidly evolving with frameworks, protocols, and tools designed to make building agents easier and more reliable.</p>\n<h3>Agent Frameworks</h3>\n<p>Several frameworks have emerged to simplify agent development:</p>\n<p><strong>Pydantic AI</strong> - A Python framework that leverages Pydantic's type system for building type-safe, validated agents. It emphasizes developer experience with clean APIs and strong typing.</p>\n<p><strong>AWS Bedrock Agents</strong> - Amazon's managed service for building agents that can securely connect to enterprise data sources and take actions. Provides infrastructure for production-grade agent deployments.</p>\n<p><strong>LangGraph</strong> - A framework for building stateful, multi-actor applications with LLMs, supporting complex agent workflows and coordination.</p>\n<h3>Interoperability Protocols</h3>\n<p>As agents become more sophisticated, standards for communication become crucial:</p>\n<p><strong>Model Context Protocol (MCP)</strong> - An open protocol developed by Anthropic for connecting AI assistants to external data sources and tools. MCP provides a standardized way to expose capabilities to LLMs.</p>\n<p><strong>Agent2Agent (A2A)</strong> - Google's protocol enabling different AI agents to communicate and collaborate, regardless of their underlying frameworks or vendors.</p>\n<h3>Observability and Monitoring</h3>\n<p>Production agents require robust monitoring:</p>\n<p><strong>Langfuse</strong> - An open-source observability platform for LLM applications. It provides tracing, analytics, and evaluation tools specifically designed for understanding agent behavior and debugging issues.</p>\n<h2>Why Agentic Architecture Matters</h2>\n<h3>Current Applications</h3>\n<p>Agents are already transforming various domains:</p>\n<ul>\n<li><strong>Coding Assistants</strong>: Autonomous code generation, debugging, and refactoring</li>\n<li><strong>Research Agents</strong>: Literature review, data analysis, and report generation</li>\n<li><strong>Customer Service</strong>: Complex issue resolution with tool access</li>\n<li><strong>Data Analysis</strong>: End-to-end analysis from data collection to visualization</li>\n<li><strong>Personal Assistants</strong>: Calendar management, email handling, task automation</li>\n</ul>\n<h3>Challenges and Considerations</h3>\n<p>Building reliable agents comes with unique challenges:</p>\n<ul>\n<li><strong>Reliability</strong>: Ensuring consistent behavior across diverse inputs</li>\n<li><strong>Safety</strong>: Preventing harmful actions, especially with tool access</li>\n<li><strong>Cost</strong>: Managing token usage and API costs at scale</li>\n<li><strong>Latency</strong>: Balancing thoroughness with response time</li>\n<li><strong>Evaluation</strong>: Measuring agent performance on open-ended tasks</li>\n</ul>\n<h2>Getting Started</h2>\n<p>If you're new to building agents, here's a recommended learning path:</p>\n<ol>\n<li><strong>Understand LLM fundamentals</strong> - Function calling, prompting techniques</li>\n<li><strong>Start with a framework</strong> - Pick one (Pydantic AI is great for Python devs)</li>\n<li><strong>Build a simple agent</strong> - A single-tool agent for a specific task</li>\n<li><strong>Add complexity gradually</strong> - Multiple tools, memory, planning</li>\n<li><strong>Implement observability</strong> - Add Langfuse or similar from the start</li>\n<li><strong>Explore protocols</strong> - Understand MCP and A2A for interoperability</li>\n</ol>\n<h2>Topics to Explore</h2>\n<p>This introduction sets the stage for deeper dives into specific aspects of agentic architecture:</p>\n<ul>\n<li><a href=\"pydantic-ai.html\">Pydantic AI</a> - Type-safe agent development in Python</li>\n<li><a href=\"bedrock-agents.html\">AWS Bedrock Agents</a> - Enterprise-grade managed agents</li>\n<li><a href=\"mcp.html\">Model Context Protocol</a> - Standardized tool and data integration</li>\n<li><a href=\"a2a.html\">Agent2Agent Protocol</a> - Multi-agent communication</li>\n<li><a href=\"langfuse.html\">Langfuse</a> - Observability for LLM applications</li>\n<li><a href=\"agent-patterns.html\">Agent Design Patterns</a> - Common architectures and best practices</li>\n</ul>\n<h2>Key Takeaways</h2>\n<ul>\n<li>Agentic systems extend LLMs with autonomy, tools, planning, and memory</li>\n<li>The observe-think-act loop is fundamental to agent behavior</li>\n<li>Multiple frameworks exist with different tradeoffs (Pydantic AI, Bedrock, etc.)</li>\n<li>Protocols like MCP and A2A enable interoperability</li>\n<li>Observability (Langfuse) is essential for production systems</li>\n<li>Start simple and add complexity as needed</li>\n</ul>\n<h2>Resources</h2>\n<h3>Documentation</h3>\n<ul>\n<li><a href=\"https://modelcontextprotocol.io/\">Anthropic MCP Documentation</a></li>\n<li><a href=\"https://ai.pydantic.dev/\">Pydantic AI Docs</a></li>\n<li><a href=\"https://docs.aws.amazon.com/bedrock/latest/userguide/agents.html\">AWS Bedrock Agents</a></li>\n<li><a href=\"https://langfuse.com/docs\">Langfuse Documentation</a></li>\n</ul>\n<h3>Papers and Research</h3>\n<ul>\n<li>\"ReAct: Synergizing Reasoning and Acting in Language Models\"</li>\n<li>\"Toolformer: Language Models Can Teach Themselves to Use Tools\"</li>\n<li>\"Generative Agents: Interactive Simulacra of Human Behavior\"</li>\n</ul>\n<hr />\n<p><strong>Last Updated:</strong> November 25, 2025<br />\n<strong>Difficulty Level:</strong> Intermediate</p>",
      "excerpt": "# Introduction to Agentic Architecture **This article is generated by Claude Opus 4.5** ## Overview Agentic architecture represents a paradigm shift in how we build AI systems. Instead of simple promp..."
    },
    {
      "id": "dl",
      "name": "Introduction to Deep Learning",
      "category": "deep-learning",
      "tags": [
        "deep learning",
        "neural networks",
        "PyTorch",
        "CNN",
        "RNN",
        "attention",
        "ai-generated"
      ],
      "date": "2025-11-24",
      "description": "Comprehensive introduction to deep learning concepts including neural networks, CNNs, RNNs, attention mechanisms, and backpropagation with PyTorch examples",
      "related": [
        "transformers"
      ],
      "file": "dl.md",
      "html": "<h1>Introduction to Deep Learning</h1>\n<p><strong>This article is generated by Claude Opus 4.5</strong></p>\n<h2>Overview</h2>\n<p>Deep Learning is a subset of machine learning that uses artificial neural networks with multiple layers (hence \"deep\") to learn complex patterns from data. It has revolutionized fields like computer vision, natural language processing, and speech recognition.</p>\n<h2>What Makes Deep Learning Different?</h2>\n<p>While traditional machine learning requires manual feature engineering, deep learning automatically learns hierarchical representations from raw data. Each layer learns increasingly abstract features.</p>\n<h3>Key Concepts</h3>\n<ul>\n<li><strong>Neural Network</strong>: A computational model inspired by biological neurons</li>\n<li><strong>Layers</strong>: Building blocks that transform input data</li>\n<li><strong>Weights &amp; Biases</strong>: Learnable parameters that the network optimizes</li>\n<li><strong>Activation Functions</strong>: Non-linear functions that enable learning complex patterns</li>\n<li><strong>Loss Function</strong>: Measures how well the model's predictions match the targets</li>\n<li><strong>Backpropagation</strong>: Algorithm for computing gradients to update weights</li>\n</ul>\n<h2>Getting Started with PyTorch</h2>\n<p>PyTorch is a popular deep learning framework known for its flexibility and Pythonic design.</p>\n<h3>Installation</h3>\n<pre><code class=\"language-bash\">pip install torch torchvision\n</code></pre>\n<h3>Basic Tensor Operations</h3>\n<pre><code class=\"language-python\">import torch\nimport torch.nn as nn\nimport torch.optim as optim\n\n# Create tensors\nx = torch.tensor([1.0, 2.0, 3.0])\ny = torch.tensor([4.0, 5.0, 6.0])\n\n# Basic operations\nz = x + y           # Element-wise addition\ndot = torch.dot(x, y)  # Dot product\n\n# Create a matrix\nmatrix = torch.randn(3, 4)  # Random 3x4 matrix\nprint(f&quot;Matrix shape: {matrix.shape}&quot;)\n\n# GPU support (if available)\ndevice = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)\ntensor_gpu = matrix.to(device)\n</code></pre>\n<h2>Neural Network Fundamentals</h2>\n<h3>The Perceptron (Single Neuron)</h3>\n<pre><code class=\"language-python\">import torch\nimport torch.nn as nn\n\nclass Perceptron(nn.Module):\n    def __init__(self, input_size):\n        super().__init__()\n        self.linear = nn.Linear(input_size, 1)\n        self.activation = nn.Sigmoid()\n\n    def forward(self, x):\n        return self.activation(self.linear(x))\n\n# Create and use perceptron\nperceptron = Perceptron(input_size=3)\ninput_data = torch.tensor([1.0, 2.0, 3.0])\noutput = perceptron(input_data)\nprint(f&quot;Output: {output.item():.4f}&quot;)\n</code></pre>\n<h3>Multi-Layer Perceptron (MLP)</h3>\n<pre><code class=\"language-python\">class MLP(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super().__init__()\n        self.network = nn.Sequential(\n            nn.Linear(input_size, hidden_size),\n            nn.ReLU(),\n            nn.Linear(hidden_size, hidden_size),\n            nn.ReLU(),\n            nn.Linear(hidden_size, output_size)\n        )\n\n    def forward(self, x):\n        return self.network(x)\n\n# Example: Classification with 10 input features, 64 hidden units, 3 classes\nmodel = MLP(input_size=10, hidden_size=64, output_size=3)\nsample_input = torch.randn(1, 10)  # Batch size 1\noutput = model(sample_input)\nprint(f&quot;Output shape: {output.shape}&quot;)  # [1, 3]\n</code></pre>\n<h2>Backpropagation</h2>\n<p>Backpropagation is the algorithm used to compute gradients of the loss with respect to each weight. It applies the chain rule of calculus to efficiently propagate errors backward through the network.</p>\n<h3>How Backpropagation Works</h3>\n<ol>\n<li><strong>Forward Pass</strong>: Compute predictions by passing input through the network</li>\n<li><strong>Compute Loss</strong>: Calculate the difference between predictions and targets</li>\n<li><strong>Backward Pass</strong>: Compute gradients using the chain rule</li>\n<li><strong>Update Weights</strong>: Adjust weights in the direction that reduces loss</li>\n</ol>\n<h3>Manual Backpropagation Example</h3>\n<pre><code class=\"language-python\">import torch\n\n# Simple network: y = w2 * relu(w1 * x + b1) + b2\nx = torch.tensor([1.0, 2.0, 3.0], requires_grad=False)\ntarget = torch.tensor([1.0])\n\n# Initialize weights with gradient tracking\nw1 = torch.randn(3, 4, requires_grad=True)\nb1 = torch.zeros(4, requires_grad=True)\nw2 = torch.randn(4, 1, requires_grad=True)\nb2 = torch.zeros(1, requires_grad=True)\n\n# Forward pass\nhidden = torch.relu(x @ w1 + b1)\noutput = hidden @ w2 + b2\n\n# Compute loss (MSE)\nloss = ((output - target) ** 2).mean()\nprint(f&quot;Loss: {loss.item():.4f}&quot;)\n\n# Backward pass - computes all gradients\nloss.backward()\n\n# Gradients are now available\nprint(f&quot;w1 gradient shape: {w1.grad.shape}&quot;)\nprint(f&quot;w2 gradient shape: {w2.grad.shape}&quot;)\n</code></pre>\n<h3>Training Loop with PyTorch</h3>\n<pre><code class=\"language-python\">import torch\nimport torch.nn as nn\nimport torch.optim as optim\n\n# Create model, loss function, and optimizer\nmodel = MLP(input_size=10, hidden_size=64, output_size=3)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# Training loop\ndef train_step(model, X_batch, y_batch):\n    model.train()\n\n    # Forward pass\n    outputs = model(X_batch)\n    loss = criterion(outputs, y_batch)\n\n    # Backward pass\n    optimizer.zero_grad()  # Clear previous gradients\n    loss.backward()        # Compute gradients\n    optimizer.step()       # Update weights\n\n    return loss.item()\n\n# Example training\nX_train = torch.randn(100, 10)  # 100 samples\ny_train = torch.randint(0, 3, (100,))  # 3 classes\n\nfor epoch in range(10):\n    loss = train_step(model, X_train, y_train)\n    print(f&quot;Epoch {epoch+1}, Loss: {loss:.4f}&quot;)\n</code></pre>\n<h2>Convolutional Neural Networks (CNNs)</h2>\n<p>CNNs are designed for processing grid-like data such as images. They use convolutional layers to automatically learn spatial hierarchies of features.</p>\n<h3>Key Components</h3>\n<ul>\n<li><strong>Convolutional Layer</strong>: Applies filters to detect local patterns</li>\n<li><strong>Pooling Layer</strong>: Reduces spatial dimensions while retaining important features</li>\n<li><strong>Stride</strong>: Step size when sliding the filter</li>\n<li><strong>Padding</strong>: Adding zeros around input to control output size</li>\n</ul>\n<h3>CNN Architecture in PyTorch</h3>\n<pre><code class=\"language-python\">import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass CNN(nn.Module):\n    def __init__(self, num_classes=10):\n        super().__init__()\n\n        # Convolutional layers\n        self.conv1 = nn.Conv2d(\n            in_channels=1,    # Grayscale image\n            out_channels=32,  # 32 filters\n            kernel_size=3,    # 3x3 filter\n            padding=1         # Same padding\n        )\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n\n        # Pooling layer\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n\n        # Batch normalization\n        self.bn1 = nn.BatchNorm2d(32)\n        self.bn2 = nn.BatchNorm2d(64)\n        self.bn3 = nn.BatchNorm2d(128)\n\n        # Fully connected layers\n        self.fc1 = nn.Linear(128 * 3 * 3, 256)  # After 3 pooling ops: 28-&gt;14-&gt;7-&gt;3\n        self.fc2 = nn.Linear(256, num_classes)\n\n        # Dropout for regularization\n        self.dropout = nn.Dropout(0.5)\n\n    def forward(self, x):\n        # Conv block 1: [B, 1, 28, 28] -&gt; [B, 32, 14, 14]\n        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n\n        # Conv block 2: [B, 32, 14, 14] -&gt; [B, 64, 7, 7]\n        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n\n        # Conv block 3: [B, 64, 7, 7] -&gt; [B, 128, 3, 3]\n        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n\n        # Flatten: [B, 128, 3, 3] -&gt; [B, 128*3*3]\n        x = x.view(x.size(0), -1)\n\n        # Fully connected layers\n        x = self.dropout(F.relu(self.fc1(x)))\n        x = self.fc2(x)\n\n        return x\n\n# Create model and test with random image\ncnn = CNN(num_classes=10)\nsample_image = torch.randn(1, 1, 28, 28)  # Batch=1, Channels=1, H=28, W=28\noutput = cnn(sample_image)\nprint(f&quot;CNN output shape: {output.shape}&quot;)  # [1, 10]\n</code></pre>\n<h3>Understanding Convolutions</h3>\n<pre><code class=\"language-python\"># Visualize what a convolution does\nimport torch\nimport torch.nn as nn\n\n# Create a simple edge detection filter\nedge_filter = torch.tensor([\n    [-1, -1, -1],\n    [-1,  8, -1],\n    [-1, -1, -1]\n], dtype=torch.float32).view(1, 1, 3, 3)\n\n# Apply to a sample image\nconv = nn.Conv2d(1, 1, kernel_size=3, padding=1, bias=False)\nconv.weight.data = edge_filter\n\nsample = torch.randn(1, 1, 8, 8)\nfiltered = conv(sample)\nprint(f&quot;Input shape: {sample.shape}, Output shape: {filtered.shape}&quot;)\n</code></pre>\n<h2>Recurrent Neural Networks (RNNs)</h2>\n<p>RNNs are designed for sequential data where the order matters (text, time series, audio). They maintain a hidden state that captures information from previous time steps.</p>\n<h3>Basic RNN</h3>\n<pre><code class=\"language-python\">import torch\nimport torch.nn as nn\n\nclass SimpleRNN(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super().__init__()\n        self.hidden_size = hidden_size\n\n        # RNN layer\n        self.rnn = nn.RNN(\n            input_size=input_size,\n            hidden_size=hidden_size,\n            num_layers=1,\n            batch_first=True  # Input shape: [batch, seq_len, features]\n        )\n\n        # Output layer\n        self.fc = nn.Linear(hidden_size, output_size)\n\n    def forward(self, x, hidden=None):\n        # x shape: [batch, seq_len, input_size]\n\n        # Initialize hidden state if not provided\n        if hidden is None:\n            hidden = torch.zeros(1, x.size(0), self.hidden_size)\n\n        # RNN forward pass\n        output, hidden = self.rnn(x, hidden)\n        # output shape: [batch, seq_len, hidden_size]\n        # hidden shape: [num_layers, batch, hidden_size]\n\n        # Take the last output for classification\n        last_output = output[:, -1, :]  # [batch, hidden_size]\n        prediction = self.fc(last_output)\n\n        return prediction, hidden\n\n# Example: Sequence classification\nrnn = SimpleRNN(input_size=10, hidden_size=64, output_size=5)\nsequence = torch.randn(32, 20, 10)  # Batch=32, SeqLen=20, Features=10\noutput, _ = rnn(sequence)\nprint(f&quot;RNN output shape: {output.shape}&quot;)  # [32, 5]\n</code></pre>\n<h3>LSTM (Long Short-Term Memory)</h3>\n<p>LSTMs solve the vanishing gradient problem in vanilla RNNs using gates that control information flow.</p>\n<pre><code class=\"language-python\">class LSTMClassifier(nn.Module):\n    def __init__(self, vocab_size, embed_dim, hidden_size, num_classes):\n        super().__init__()\n\n        # Embedding layer for text\n        self.embedding = nn.Embedding(vocab_size, embed_dim)\n\n        # LSTM layer\n        self.lstm = nn.LSTM(\n            input_size=embed_dim,\n            hidden_size=hidden_size,\n            num_layers=2,\n            batch_first=True,\n            dropout=0.3,\n            bidirectional=True  # Process sequence both directions\n        )\n\n        # Output layer (bidirectional doubles hidden size)\n        self.fc = nn.Linear(hidden_size * 2, num_classes)\n\n    def forward(self, x):\n        # x shape: [batch, seq_len] - token indices\n\n        # Embed tokens\n        embedded = self.embedding(x)  # [batch, seq_len, embed_dim]\n\n        # LSTM forward pass\n        lstm_out, (hidden, cell) = self.lstm(embedded)\n        # lstm_out: [batch, seq_len, hidden_size*2]\n        # hidden: [num_layers*2, batch, hidden_size]\n\n        # Concatenate final hidden states from both directions\n        hidden_cat = torch.cat([hidden[-2], hidden[-1]], dim=1)\n\n        # Classification\n        output = self.fc(hidden_cat)\n        return output\n\n# Example: Text classification\nlstm_model = LSTMClassifier(vocab_size=10000, embed_dim=128, hidden_size=256, num_classes=3)\ntext_input = torch.randint(0, 10000, (16, 50))  # Batch=16, SeqLen=50\noutput = lstm_model(text_input)\nprint(f&quot;LSTM output shape: {output.shape}&quot;)  # [16, 3]\n</code></pre>\n<h3>GRU (Gated Recurrent Unit)</h3>\n<p>GRUs are a simpler alternative to LSTMs with fewer parameters.</p>\n<pre><code class=\"language-python\">class GRUModel(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size, num_layers=2):\n        super().__init__()\n\n        self.gru = nn.GRU(\n            input_size=input_size,\n            hidden_size=hidden_size,\n            num_layers=num_layers,\n            batch_first=True,\n            dropout=0.2\n        )\n\n        self.fc = nn.Linear(hidden_size, output_size)\n\n    def forward(self, x):\n        output, hidden = self.gru(x)\n        # Use last time step output\n        return self.fc(output[:, -1, :])\n\n# Time series prediction\ngru = GRUModel(input_size=1, hidden_size=64, output_size=1)\ntime_series = torch.randn(32, 100, 1)  # 100 time steps\nprediction = gru(time_series)\nprint(f&quot;GRU prediction shape: {prediction.shape}&quot;)  # [32, 1]\n</code></pre>\n<h2>Attention Mechanisms</h2>\n<p>Attention allows models to focus on relevant parts of the input when making predictions. It's the foundation of modern architectures like Transformers.</p>\n<h3>Basic Attention</h3>\n<pre><code class=\"language-python\">import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Attention(nn.Module):\n    &quot;&quot;&quot;Simple additive attention mechanism.&quot;&quot;&quot;\n\n    def __init__(self, hidden_size):\n        super().__init__()\n        self.attention = nn.Linear(hidden_size, 1)\n\n    def forward(self, encoder_outputs):\n        # encoder_outputs: [batch, seq_len, hidden_size]\n\n        # Compute attention scores\n        scores = self.attention(encoder_outputs)  # [batch, seq_len, 1]\n        scores = scores.squeeze(-1)  # [batch, seq_len]\n\n        # Softmax to get attention weights\n        weights = F.softmax(scores, dim=1)  # [batch, seq_len]\n\n        # Weighted sum of encoder outputs\n        context = torch.bmm(\n            weights.unsqueeze(1),  # [batch, 1, seq_len]\n            encoder_outputs         # [batch, seq_len, hidden_size]\n        ).squeeze(1)  # [batch, hidden_size]\n\n        return context, weights\n</code></pre>\n<h3>Scaled Dot-Product Attention</h3>\n<p>This is the attention mechanism used in Transformers.</p>\n<pre><code class=\"language-python\">class ScaledDotProductAttention(nn.Module):\n    def __init__(self, d_k):\n        super().__init__()\n        self.scale = d_k ** 0.5\n\n    def forward(self, query, key, value, mask=None):\n        &quot;&quot;&quot;\n        Args:\n            query: [batch, seq_len, d_k]\n            key: [batch, seq_len, d_k]\n            value: [batch, seq_len, d_v]\n            mask: Optional mask for padding or causal attention\n        &quot;&quot;&quot;\n        # Compute attention scores\n        scores = torch.bmm(query, key.transpose(1, 2)) / self.scale\n        # scores: [batch, seq_len, seq_len]\n\n        # Apply mask if provided\n        if mask is not None:\n            scores = scores.masked_fill(mask == 0, float('-inf'))\n\n        # Softmax to get attention weights\n        attention_weights = F.softmax(scores, dim=-1)\n\n        # Weighted sum of values\n        output = torch.bmm(attention_weights, value)\n\n        return output, attention_weights\n\n# Example usage\nd_k = 64\nattention = ScaledDotProductAttention(d_k)\n\nbatch_size, seq_len = 8, 20\nQ = torch.randn(batch_size, seq_len, d_k)\nK = torch.randn(batch_size, seq_len, d_k)\nV = torch.randn(batch_size, seq_len, d_k)\n\noutput, weights = attention(Q, K, V)\nprint(f&quot;Attention output shape: {output.shape}&quot;)  # [8, 20, 64]\nprint(f&quot;Attention weights shape: {weights.shape}&quot;)  # [8, 20, 20]\n</code></pre>\n<h3>Multi-Head Attention</h3>\n<p>Multi-head attention allows the model to attend to different representation subspaces.</p>\n<pre><code class=\"language-python\">class MultiHeadAttention(nn.Module):\n    def __init__(self, d_model, num_heads):\n        super().__init__()\n        assert d_model % num_heads == 0\n\n        self.d_model = d_model\n        self.num_heads = num_heads\n        self.d_k = d_model // num_heads\n\n        # Linear projections for Q, K, V\n        self.W_q = nn.Linear(d_model, d_model)\n        self.W_k = nn.Linear(d_model, d_model)\n        self.W_v = nn.Linear(d_model, d_model)\n\n        # Output projection\n        self.W_o = nn.Linear(d_model, d_model)\n\n        self.attention = ScaledDotProductAttention(self.d_k)\n\n    def forward(self, query, key, value, mask=None):\n        batch_size = query.size(0)\n\n        # Linear projections and reshape for multi-head\n        Q = self.W_q(query).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n        K = self.W_k(key).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n        V = self.W_v(value).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n        # Q, K, V shape: [batch, num_heads, seq_len, d_k]\n\n        # Reshape for batch matrix multiplication\n        Q = Q.reshape(batch_size * self.num_heads, -1, self.d_k)\n        K = K.reshape(batch_size * self.num_heads, -1, self.d_k)\n        V = V.reshape(batch_size * self.num_heads, -1, self.d_k)\n\n        # Apply attention\n        attended, weights = self.attention(Q, K, V, mask)\n\n        # Reshape back\n        attended = attended.view(batch_size, self.num_heads, -1, self.d_k)\n        attended = attended.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n\n        # Final linear projection\n        output = self.W_o(attended)\n\n        return output\n\n# Example\nmha = MultiHeadAttention(d_model=512, num_heads=8)\nx = torch.randn(4, 30, 512)  # Batch=4, SeqLen=30, Dim=512\noutput = mha(x, x, x)  # Self-attention\nprint(f&quot;Multi-head attention output: {output.shape}&quot;)  # [4, 30, 512]\n</code></pre>\n<h3>Self-Attention with RNN</h3>\n<p>Combining attention with RNNs for sequence classification.</p>\n<pre><code class=\"language-python\">class AttentionRNN(nn.Module):\n    def __init__(self, vocab_size, embed_dim, hidden_size, num_classes):\n        super().__init__()\n\n        self.embedding = nn.Embedding(vocab_size, embed_dim)\n\n        self.lstm = nn.LSTM(\n            embed_dim, hidden_size,\n            batch_first=True, bidirectional=True\n        )\n\n        self.attention = Attention(hidden_size * 2)\n        self.fc = nn.Linear(hidden_size * 2, num_classes)\n\n    def forward(self, x):\n        # Embed\n        embedded = self.embedding(x)\n\n        # LSTM encoding\n        lstm_out, _ = self.lstm(embedded)\n\n        # Apply attention to get context vector\n        context, attention_weights = self.attention(lstm_out)\n\n        # Classify\n        output = self.fc(context)\n\n        return output, attention_weights\n\n# Example\nmodel = AttentionRNN(vocab_size=5000, embed_dim=128, hidden_size=128, num_classes=2)\ntext = torch.randint(0, 5000, (8, 50))\noutput, attn_weights = model(text)\nprint(f&quot;Output: {output.shape}, Attention: {attn_weights.shape}&quot;)\n</code></pre>\n<h2>Complete Training Example</h2>\n<p>Here's a full example training a CNN on image classification:</p>\n<pre><code class=\"language-python\">import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\n\n# Model\nclass ImageClassifier(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(3, 32, 3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n            nn.Conv2d(32, 64, 3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2),\n            nn.Conv2d(64, 128, 3, padding=1),\n            nn.ReLU(),\n            nn.AdaptiveAvgPool2d(1)\n        )\n        self.classifier = nn.Linear(128, 10)\n\n    def forward(self, x):\n        x = self.features(x)\n        x = x.view(x.size(0), -1)\n        return self.classifier(x)\n\n# Training function\ndef train(model, train_loader, epochs=10, device='cpu'):\n    model = model.to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n\n    for epoch in range(epochs):\n        model.train()\n        total_loss = 0\n        correct = 0\n        total = 0\n\n        for batch_x, batch_y in train_loader:\n            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(batch_x)\n            loss = criterion(outputs, batch_y)\n            loss.backward()\n            optimizer.step()\n\n            total_loss += loss.item()\n            _, predicted = outputs.max(1)\n            correct += predicted.eq(batch_y).sum().item()\n            total += batch_y.size(0)\n\n        scheduler.step()\n\n        accuracy = 100. * correct / total\n        print(f&quot;Epoch {epoch+1}/{epochs} - Loss: {total_loss:.4f} - Accuracy: {accuracy:.2f}%&quot;)\n\n# Create sample data and train\nX = torch.randn(1000, 3, 32, 32)  # 1000 RGB images 32x32\ny = torch.randint(0, 10, (1000,))  # 10 classes\n\ndataset = TensorDataset(X, y)\nloader = DataLoader(dataset, batch_size=32, shuffle=True)\n\nmodel = ImageClassifier()\ntrain(model, loader, epochs=5)\n</code></pre>\n<h2>Activation Functions</h2>\n<pre><code class=\"language-python\">import torch\nimport torch.nn.functional as F\n\nx = torch.linspace(-5, 5, 100)\n\n# Common activation functions\nrelu = F.relu(x)           # max(0, x)\nsigmoid = torch.sigmoid(x)  # 1 / (1 + e^-x)\ntanh = torch.tanh(x)        # (e^x - e^-x) / (e^x + e^-x)\nleaky_relu = F.leaky_relu(x, 0.01)  # x if x &gt; 0 else 0.01*x\ngelu = F.gelu(x)            # Used in Transformers\n\n# In a model\nmodel = nn.Sequential(\n    nn.Linear(10, 64),\n    nn.GELU(),  # or nn.ReLU(), nn.LeakyReLU(), etc.\n    nn.Linear(64, 10)\n)\n</code></pre>\n<h2>Loss Functions</h2>\n<pre><code class=\"language-python\"># Classification\nce_loss = nn.CrossEntropyLoss()      # Multi-class\nbce_loss = nn.BCEWithLogitsLoss()    # Binary\n\n# Regression\nmse_loss = nn.MSELoss()              # Mean Squared Error\nmae_loss = nn.L1Loss()               # Mean Absolute Error\nhuber_loss = nn.SmoothL1Loss()       # Robust to outliers\n\n# Sequence models\nctc_loss = nn.CTCLoss()              # Speech recognition\n\n# Example usage\npredictions = torch.randn(32, 10)    # 32 samples, 10 classes\ntargets = torch.randint(0, 10, (32,))\nloss = ce_loss(predictions, targets)\n</code></pre>\n<h2>Key Takeaways</h2>\n<ul>\n<li>Deep learning uses multiple layers to learn hierarchical representations</li>\n<li>Backpropagation efficiently computes gradients using the chain rule</li>\n<li>CNNs excel at spatial data (images) using convolutional filters</li>\n<li>RNNs/LSTMs/GRUs process sequential data with memory</li>\n<li>Attention mechanisms allow models to focus on relevant input parts</li>\n<li>PyTorch provides a flexible framework for building and training models</li>\n<li>Always use GPU acceleration when available for faster training</li>\n</ul>\n<h2>Resources for Learning</h2>\n<h3>Online Courses</h3>\n<ul>\n<li><a href=\"https://www.coursera.org/specializations/deep-learning\">Deep Learning Specialization (Coursera)</a></li>\n<li><a href=\"https://course.fast.ai/\">Fast.ai Practical Deep Learning</a></li>\n<li><a href=\"http://cs231n.stanford.edu/\">Stanford CS231n: CNNs for Visual Recognition</a></li>\n<li><a href=\"http://web.stanford.edu/class/cs224n/\">Stanford CS224n: NLP with Deep Learning</a></li>\n</ul>\n<h3>Books</h3>\n<ul>\n<li>\"Deep Learning\" by Goodfellow, Bengio, and Courville</li>\n<li>\"Dive into Deep Learning\" (d2l.ai) - Free online book</li>\n<li>\"Neural Networks and Deep Learning\" by Michael Nielsen</li>\n</ul>\n<h3>Documentation</h3>\n<ul>\n<li><a href=\"https://pytorch.org/docs/\">PyTorch Documentation</a></li>\n<li><a href=\"https://pytorch.org/tutorials/\">PyTorch Tutorials</a></li>\n</ul>\n<h2>Related Topics</h2>\n<ul>\n<li><a href=\"ml.html\">Machine Learning Fundamentals</a> - ML basics before diving into DL</li>\n<li><a href=\"python.html\">Python Basics</a> - Programming foundation</li>\n<li><a href=\"transformers.html\">Transformers</a> - Modern attention-based architectures</li>\n</ul>\n<h2>Tools and Libraries</h2>\n<ul>\n<li><strong>PyTorch</strong>: Flexible deep learning framework</li>\n<li><strong>TensorFlow/Keras</strong>: Alternative framework by Google</li>\n<li><strong>Hugging Face</strong>: Pre-trained models and datasets</li>\n<li><strong>Weights &amp; Biases</strong>: Experiment tracking</li>\n<li><strong>TensorBoard</strong>: Visualization toolkit</li>\n</ul>\n<hr />\n<p><strong>Last Updated:</strong> November 24, 2025<br />\n<strong>Difficulty Level:</strong> Intermediate</p>",
      "excerpt": "# Introduction to Deep Learning **This article is generated by Claude Opus 4.5** ## Overview Deep Learning is a subset of machine learning that uses artificial neural networks with multiple layers (he..."
    },
    {
      "id": "ml",
      "name": "Machine Learning Fundamentals",
      "category": "machine-learning",
      "tags": [
        "machine learning",
        "AI",
        "algorithms",
        "supervised learning",
        "ai-generated"
      ],
      "date": "2025-11-08",
      "description": "Introduction to machine learning concepts, algorithms, and applications",
      "related": [
        "python"
      ],
      "file": "ml.md",
      "html": "<h1>Machine Learning Fundamentals</h1>\n<p><strong>This article is generated by Claude Opus 4.5</strong></p>\n<h2>Overview</h2>\n<p>Machine Learning (ML) is a subset of artificial intelligence that focuses on building systems that can learn from and make decisions based on data. Instead of being explicitly programmed, these systems improve their performance through experience.</p>\n<h2>What is Machine Learning?</h2>\n<p>Machine Learning enables computers to learn patterns from data without being explicitly programmed for every scenario. It's the foundation of many modern AI applications, from recommendation systems to autonomous vehicles.</p>\n<h3>Key Concepts</h3>\n<ul>\n<li><strong>Training Data</strong>: Historical data used to teach the model</li>\n<li><strong>Features</strong>: Input variables used to make predictions</li>\n<li><strong>Labels</strong>: The output we want to predict (in supervised learning)</li>\n<li><strong>Model</strong>: The mathematical representation of patterns in data</li>\n</ul>\n<h2>Types of Machine Learning</h2>\n<h3>1. Supervised Learning</h3>\n<p>The algorithm learns from labeled training data, making predictions based on that data.</p>\n<p><strong>Examples:</strong>\n- Classification (spam detection, image recognition)\n- Regression (price prediction, weather forecasting)</p>\n<pre><code class=\"language-python\"># Simple supervised learning example with sklearn\nfrom sklearn.linear_model import LinearRegression\nimport numpy as np\n\n# Training data\nX = np.array([[1], [2], [3], [4], [5]])\ny = np.array([2, 4, 6, 8, 10])\n\n# Create and train model\nmodel = LinearRegression()\nmodel.fit(X, y)\n\n# Make prediction\nprediction = model.predict([[6]])\nprint(f&quot;Prediction for 6: {prediction[0]}&quot;)  # Output: ~12\n</code></pre>\n<h3>2. Unsupervised Learning</h3>\n<p>The algorithm finds patterns in unlabeled data.</p>\n<p><strong>Examples:</strong>\n- Clustering (customer segmentation)\n- Dimensionality reduction (data compression)\n- Anomaly detection</p>\n<h3>3. Reinforcement Learning</h3>\n<p>The algorithm learns through trial and error, receiving rewards or penalties.</p>\n<p><strong>Examples:</strong>\n- Game playing (AlphaGo, Chess engines)\n- Robotics\n- Resource optimization</p>\n<h2>Common Algorithms</h2>\n<h3>Linear Regression</h3>\n<p>Predicts continuous values based on linear relationships.</p>\n<h3>Logistic Regression</h3>\n<p>Classification algorithm for binary outcomes.</p>\n<h3>Decision Trees</h3>\n<p>Tree-like model for classification and regression.</p>\n<h3>Neural Networks</h3>\n<p>Inspired by biological neurons, forms the basis of deep learning.</p>\n<h3>Support Vector Machines (SVM)</h3>\n<p>Finds optimal boundaries between classes.</p>\n<h3>K-Means Clustering</h3>\n<p>Groups similar data points together.</p>\n<h2>The ML Workflow</h2>\n<ol>\n<li><strong>Problem Definition</strong>: What are we trying to predict or understand?</li>\n<li><strong>Data Collection</strong>: Gather relevant data</li>\n<li><strong>Data Preprocessing</strong>: Clean and prepare data</li>\n<li><strong>Feature Engineering</strong>: Create meaningful features</li>\n<li><strong>Model Selection</strong>: Choose appropriate algorithm</li>\n<li><strong>Training</strong>: Teach the model with training data</li>\n<li><strong>Evaluation</strong>: Test model performance</li>\n<li><strong>Deployment</strong>: Use the model in production</li>\n<li><strong>Monitoring</strong>: Track performance over time</li>\n</ol>\n<h2>Practical Example: Predicting House Prices</h2>\n<pre><code class=\"language-python\">import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\n\n# Load data\ndata = pd.DataFrame({\n    'size': [1500, 1600, 1700, 1800, 1900],\n    'bedrooms': [3, 3, 4, 4, 5],\n    'age': [10, 15, 20, 5, 8],\n    'price': [300000, 320000, 340000, 380000, 400000]\n})\n\n# Prepare features and target\nX = data[['size', 'bedrooms', 'age']]\ny = data['price']\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\n# Train model\nmodel = RandomForestRegressor(n_estimators=100)\nmodel.fit(X_train, y_train)\n\n# Evaluate\npredictions = model.predict(X_test)\nmse = mean_squared_error(y_test, predictions)\nprint(f&quot;Mean Squared Error: {mse}&quot;)\n</code></pre>\n<h2>Resources for Learning</h2>\n<h3>Online Courses</h3>\n<ul>\n<li><a href=\"https://www.coursera.org/learn/machine-learning\">Coursera: Machine Learning by Andrew Ng</a></li>\n<li><a href=\"https://www.fast.ai/\">Fast.ai: Practical Deep Learning</a></li>\n</ul>\n<h3>Books</h3>\n<ul>\n<li>\"Hands-On Machine Learning\" by Aur\u00e9lien G\u00e9ron</li>\n<li>\"Pattern Recognition and Machine Learning\" by Christopher Bishop</li>\n</ul>\n<h3>Practice Platforms</h3>\n<ul>\n<li><a href=\"https://www.kaggle.com\">Kaggle</a> - Competitions and datasets</li>\n<li><a href=\"https://colab.research.google.com\">Google Colab</a> - Free GPU for experiments</li>\n</ul>\n<h2>Key Takeaways</h2>\n<ul>\n<li>Machine Learning enables computers to learn from data</li>\n<li>Three main types: Supervised, Unsupervised, and Reinforcement Learning</li>\n<li>The ML workflow is iterative and requires continuous improvement</li>\n<li>Start with simple algorithms before moving to complex ones</li>\n<li>Practice is essential - work on real projects and datasets</li>\n</ul>\n<h2>Related Topics</h2>\n<ul>\n<li><a href=\"dl.html\">Deep Learning</a> - Neural networks and advanced architectures</li>\n<li><a href=\"python.html\">Python Basics</a> - Programming fundamentals for ML</li>\n<li><a href=\"statistics.html\">Statistics</a> - Mathematical foundations</li>\n</ul>\n<h2>Tools and Libraries</h2>\n<ul>\n<li><strong>Scikit-learn</strong>: General-purpose ML library</li>\n<li><strong>TensorFlow</strong>: Deep learning framework</li>\n<li><strong>PyTorch</strong>: Deep learning framework</li>\n<li><strong>Pandas</strong>: Data manipulation</li>\n<li><strong>NumPy</strong>: Numerical computing</li>\n</ul>\n<hr />\n<p><strong>Last Updated:</strong> November 8, 2025<br />\n<strong>Difficulty Level:</strong> Beginner to Intermediate</p>",
      "excerpt": "# Machine Learning Fundamentals **This article is generated by Claude Opus 4.5** ## Overview Machine Learning (ML) is a subset of artificial intelligence that focuses on building systems that can lear..."
    },
    {
      "id": "python",
      "name": "Python Programming Basics",
      "category": "machine-learning",
      "tags": [
        "python",
        "programming",
        "basics",
        "tutorial",
        "ai-generated"
      ],
      "date": "2025-11-08",
      "description": "Essential Python programming concepts for beginners",
      "related": [
        "ml"
      ],
      "file": "python.md",
      "html": "<h1>Python Programming Basics</h1>\n<p><strong>This article is generated by Claude Opus 4.5</strong></p>\n<h2>Overview</h2>\n<p>Python is a high-level, interpreted programming language known for its simplicity and readability. It's one of the most popular languages for data science, machine learning, web development, and automation.</p>\n<h2>Why Python?</h2>\n<ul>\n<li><strong>Easy to Learn</strong>: Clean, readable syntax</li>\n<li><strong>Versatile</strong>: Web dev, data science, automation, AI</li>\n<li><strong>Large Community</strong>: Extensive libraries and support</li>\n<li><strong>Cross-platform</strong>: Works on Windows, Mac, Linux</li>\n<li><strong>Free and Open Source</strong>: No licensing costs</li>\n</ul>\n<h2>Getting Started</h2>\n<h3>Installation</h3>\n<p>Visit <a href=\"https://www.python.org/downloads/\">python.org</a> to download Python.</p>\n<pre><code class=\"language-bash\"># Check if Python is installed\npython --version\n\n# Or\npython3 --version\n</code></pre>\n<h3>Your First Program</h3>\n<pre><code class=\"language-python\"># hello.py\nprint(&quot;Hello, World!&quot;)\n</code></pre>\n<p>Run it:</p>\n<pre><code class=\"language-bash\">python hello.py\n</code></pre>\n<h2>Basic Syntax</h2>\n<h3>Variables</h3>\n<pre><code class=\"language-python\"># Variables (no declaration needed)\nname = &quot;Alice&quot;\nage = 25\nheight = 5.6\nis_student = True\n\n# Multiple assignment\nx, y, z = 1, 2, 3\n</code></pre>\n<h3>Data Types</h3>\n<pre><code class=\"language-python\"># Integers\ncount = 10\n\n# Floats\nprice = 19.99\n\n# Strings\nmessage = &quot;Hello, Python!&quot;\n\n# Booleans\nis_active = True\n\n# Lists\nfruits = [&quot;apple&quot;, &quot;banana&quot;, &quot;cherry&quot;]\n\n# Tuples (immutable)\ncoordinates = (10, 20)\n\n# Dictionaries\nperson = {\n    &quot;name&quot;: &quot;Alice&quot;,\n    &quot;age&quot;: 25,\n    &quot;city&quot;: &quot;New York&quot;\n}\n\n# Sets (unique elements)\nunique_numbers = {1, 2, 3, 4}\n</code></pre>\n<h2>Control Flow</h2>\n<h3>Conditionals</h3>\n<pre><code class=\"language-python\"># if-elif-else\nage = 18\n\nif age &lt; 18:\n    print(&quot;Minor&quot;)\nelif age == 18:\n    print(&quot;Just became an adult&quot;)\nelse:\n    print(&quot;Adult&quot;)\n</code></pre>\n<h3>Loops</h3>\n<pre><code class=\"language-python\"># for loop\nfruits = [&quot;apple&quot;, &quot;banana&quot;, &quot;cherry&quot;]\nfor fruit in fruits:\n    print(fruit)\n\n# range()\nfor i in range(5):  # 0 to 4\n    print(i)\n\n# while loop\ncount = 0\nwhile count &lt; 5:\n    print(count)\n    count += 1\n</code></pre>\n<h2>Functions</h2>\n<pre><code class=\"language-python\"># Basic function\ndef greet(name):\n    return f&quot;Hello, {name}!&quot;\n\nmessage = greet(&quot;Alice&quot;)\nprint(message)  # Hello, Alice!\n\n# Default parameters\ndef power(base, exponent=2):\n    return base ** exponent\n\nprint(power(3))      # 9 (3^2)\nprint(power(3, 3))   # 27 (3^3)\n\n# Multiple return values\ndef get_stats(numbers):\n    return min(numbers), max(numbers), sum(numbers)\n\nminimum, maximum, total = get_stats([1, 2, 3, 4, 5])\n</code></pre>\n<h2>Lists and List Comprehensions</h2>\n<pre><code class=\"language-python\"># List operations\nnumbers = [1, 2, 3, 4, 5]\n\nnumbers.append(6)        # Add to end\nnumbers.insert(0, 0)     # Insert at position\nnumbers.remove(3)        # Remove value\nnumbers.pop()            # Remove last item\n\n# Slicing\nfirst_three = numbers[:3]\nlast_two = numbers[-2:]\n\n# List comprehension\nsquares = [x**2 for x in range(10)]\n# [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n\nevens = [x for x in range(20) if x % 2 == 0]\n# [0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n</code></pre>\n<h2>Dictionaries</h2>\n<pre><code class=\"language-python\"># Creating and accessing\nstudent = {\n    &quot;name&quot;: &quot;Alice&quot;,\n    &quot;age&quot;: 20,\n    &quot;grades&quot;: [85, 90, 92]\n}\n\nprint(student[&quot;name&quot;])           # Alice\nprint(student.get(&quot;age&quot;))        # 20\nprint(student.get(&quot;email&quot;, &quot;N/A&quot;))  # N/A (default)\n\n# Adding/updating\nstudent[&quot;email&quot;] = &quot;alice@example.com&quot;\nstudent[&quot;age&quot;] = 21\n\n# Iterating\nfor key, value in student.items():\n    print(f&quot;{key}: {value}&quot;)\n</code></pre>\n<h2>Classes and Objects</h2>\n<pre><code class=\"language-python\"># Define a class\nclass Dog:\n    def __init__(self, name, age):\n        self.name = name\n        self.age = age\n\n    def bark(self):\n        return f&quot;{self.name} says Woof!&quot;\n\n    def get_age_in_dog_years(self):\n        return self.age * 7\n\n# Create objects\nmy_dog = Dog(&quot;Buddy&quot;, 3)\nprint(my_dog.bark())                    # Buddy says Woof!\nprint(my_dog.get_age_in_dog_years())   # 21\n</code></pre>\n<h2>File Handling</h2>\n<pre><code class=\"language-python\"># Writing to a file\nwith open(&quot;output.txt&quot;, &quot;w&quot;) as file:\n    file.write(&quot;Hello, World!\\n&quot;)\n    file.write(&quot;Python is awesome!&quot;)\n\n# Reading from a file\nwith open(&quot;output.txt&quot;, &quot;r&quot;) as file:\n    content = file.read()\n    print(content)\n\n# Reading line by line\nwith open(&quot;output.txt&quot;, &quot;r&quot;) as file:\n    for line in file:\n        print(line.strip())\n</code></pre>\n<h2>Error Handling</h2>\n<pre><code class=\"language-python\"># try-except\ntry:\n    result = 10 / 0\nexcept ZeroDivisionError:\n    print(&quot;Cannot divide by zero!&quot;)\nexcept Exception as e:\n    print(f&quot;An error occurred: {e}&quot;)\nfinally:\n    print(&quot;This always executes&quot;)\n\n# Raising exceptions\ndef divide(a, b):\n    if b == 0:\n        raise ValueError(&quot;Divisor cannot be zero&quot;)\n    return a / b\n</code></pre>\n<h2>Modules and Imports</h2>\n<pre><code class=\"language-python\"># Importing standard library\nimport math\nprint(math.pi)           # 3.141592653589793\nprint(math.sqrt(16))     # 4.0\n\n# Import specific functions\nfrom math import pi, sqrt\nprint(pi)\n\n# Import with alias\nimport numpy as np\nimport pandas as pd\n\n# Your own modules\n# In mymodule.py:\ndef my_function():\n    return &quot;Hello from module&quot;\n\n# In main.py:\nimport mymodule\nprint(mymodule.my_function())\n</code></pre>\n<h2>Useful Built-in Functions</h2>\n<pre><code class=\"language-python\"># len() - length\nprint(len([1, 2, 3]))        # 3\nprint(len(&quot;Hello&quot;))          # 5\n\n# type() - check type\nprint(type(42))              # &lt;class 'int'&gt;\n\n# range() - sequence of numbers\nlist(range(5))               # [0, 1, 2, 3, 4]\n\n# enumerate() - index and value\nfor i, fruit in enumerate([&quot;apple&quot;, &quot;banana&quot;]):\n    print(f&quot;{i}: {fruit}&quot;)\n\n# zip() - combine iterables\nnames = [&quot;Alice&quot;, &quot;Bob&quot;]\nages = [25, 30]\nfor name, age in zip(names, ages):\n    print(f&quot;{name} is {age}&quot;)\n\n# map() - apply function\nnumbers = [1, 2, 3, 4]\nsquared = list(map(lambda x: x**2, numbers))\n# [1, 4, 9, 16]\n\n# filter() - filter elements\nevens = list(filter(lambda x: x % 2 == 0, numbers))\n# [2, 4]\n</code></pre>\n<h2>Common Mistakes to Avoid</h2>\n<ol>\n<li><strong>Indentation Errors</strong>: Python uses indentation (not brackets)</li>\n<li><strong>Mutable Default Arguments</strong>: Don't use mutable defaults in functions</li>\n<li><strong>Not Closing Files</strong>: Use <code>with</code> statement</li>\n<li><strong>Index Out of Range</strong>: Check list length before accessing</li>\n<li><strong>Integer Division</strong>: Use <code>//</code> for floor division, <code>/</code> for float</li>\n</ol>\n<h2>Practice Projects</h2>\n<h3>Beginner</h3>\n<ul>\n<li>Calculator</li>\n<li>To-do list</li>\n<li>Number guessing game</li>\n<li>Password generator</li>\n</ul>\n<h3>Intermediate</h3>\n<ul>\n<li>Web scraper</li>\n<li>Data analyzer</li>\n<li>Simple game (snake, tic-tac-toe)</li>\n<li>API consumer</li>\n</ul>\n<h2>Essential Libraries</h2>\n<pre><code class=\"language-python\"># Data Science\nimport numpy as np         # Numerical computing\nimport pandas as pd        # Data manipulation\nimport matplotlib.pyplot as plt  # Visualization\n\n# Web Development\nfrom flask import Flask    # Web framework\nimport requests           # HTTP requests\n\n# Automation\nimport os                 # Operating system\nimport sys                # System-specific\nfrom pathlib import Path  # File paths\n</code></pre>\n<h2>Resources for Learning</h2>\n<h3>Online Platforms</h3>\n<ul>\n<li><a href=\"https://docs.python.org/3/tutorial/\">Python.org Tutorial</a></li>\n<li><a href=\"https://realpython.com/\">Real Python</a></li>\n<li><a href=\"https://www.py4e.com/\">Python for Everybody</a></li>\n</ul>\n<h3>Practice</h3>\n<ul>\n<li><a href=\"https://leetcode.com/\">LeetCode</a> - Coding challenges</li>\n<li><a href=\"https://www.hackerrank.com/\">HackerRank</a> - Python track</li>\n<li><a href=\"https://projecteuler.net/\">Project Euler</a> - Math problems</li>\n</ul>\n<h3>Books</h3>\n<ul>\n<li>\"Python Crash Course\" by Eric Matthes</li>\n<li>\"Automate the Boring Stuff with Python\" by Al Sweigart</li>\n<li>\"Fluent Python\" by Luciano Ramalho (Advanced)</li>\n</ul>\n<h2>Google Colab Example</h2>\n<p>Try this code in <a href=\"https://colab.research.google.com\">Google Colab</a>:</p>\n<pre><code class=\"language-python\"># Data analysis example\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Create sample data\ndata = {\n    'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n    'Age': [25, 30, 35, 28],\n    'Score': [85, 90, 78, 92]\n}\n\ndf = pd.DataFrame(data)\nprint(df)\n\n# Plot\nplt.bar(df['Name'], df['Score'])\nplt.title('Student Scores')\nplt.xlabel('Name')\nplt.ylabel('Score')\nplt.show()\n</code></pre>\n<h2>Key Takeaways</h2>\n<ul>\n<li>Python is beginner-friendly with clean syntax</li>\n<li>Strong typing but dynamically typed</li>\n<li>Indentation matters (use 4 spaces)</li>\n<li>Rich standard library and ecosystem</li>\n<li>Great for automation, data science, and web development</li>\n<li>Practice is essential - code daily!</li>\n</ul>\n<h2>Related Topics</h2>\n<ul>\n<li><a href=\"ml.html\">Machine Learning</a> - Use Python for ML</li>\n<li><a href=\"numpy.html\">NumPy</a> - Numerical computing library</li>\n<li><a href=\"data-structures.html\">Data Structures</a> - Core CS concepts</li>\n</ul>\n<h2>Next Steps</h2>\n<ol>\n<li>Install Python on your machine</li>\n<li>Complete a beginner tutorial</li>\n<li>Build small projects</li>\n<li>Learn a library (NumPy, Pandas, or Flask)</li>\n<li>Contribute to open source</li>\n</ol>\n<hr />\n<p><strong>Last Updated:</strong> November 8, 2025<br />\n<strong>Difficulty Level:</strong> Beginner</p>",
      "excerpt": "# Python Programming Basics **This article is generated by Claude Opus 4.5** ## Overview Python is a high-level, interpreted programming language known for its simplicity and readability. It's one of ..."
    }
  ],
  "links": [
    {
      "source": "optimization",
      "target": "dl"
    },
    {
      "source": "kmeans",
      "target": "ml"
    },
    {
      "source": "crossentropy",
      "target": "dl"
    },
    {
      "source": "configuration",
      "target": "llm"
    },
    {
      "source": "configuration",
      "target": "temperature"
    },
    {
      "source": "fewshot",
      "target": "llm"
    },
    {
      "source": "evaluation",
      "target": "llm"
    },
    {
      "source": "ner",
      "target": "dl"
    },
    {
      "source": "finetuning",
      "target": "llm"
    },
    {
      "source": "finetuning",
      "target": "evaluation"
    },
    {
      "source": "faq",
      "target": "llm"
    },
    {
      "source": "temperature",
      "target": "llm"
    },
    {
      "source": "temperature",
      "target": "configuration"
    },
    {
      "source": "quantization",
      "target": "finetuning"
    },
    {
      "source": "quantization",
      "target": "dl"
    },
    {
      "source": "quantization_2",
      "target": "finetuning"
    },
    {
      "source": "quantization_2",
      "target": "quantization"
    },
    {
      "source": "quantization_2",
      "target": "dl"
    },
    {
      "source": "reinvent",
      "target": "reinvent_2"
    },
    {
      "source": "reinvent_2",
      "target": "reinvent"
    },
    {
      "source": "langchain_tools",
      "target": "agentic-architecture"
    },
    {
      "source": "agentic-architecture",
      "target": "llm"
    },
    {
      "source": "dl",
      "target": "transformers"
    },
    {
      "source": "ml",
      "target": "python"
    },
    {
      "source": "python",
      "target": "ml"
    }
  ]
}