---
title: "Quantization 1"
id: "quantization"
category: "deep-learning"
tags: ["deep learning", "dl", "quantization", "medium"]
related: ["finetuning", "dl"]
date: "2024-05-05"
description: "Unlocking the Power of Quantization: From Float32 to Int8"
---

[Read the full version on Medium](https://medium.com/@balci.pelin/quantization-1-d05e5a61e0af) 

Why do we need quantization?
* Shrink models to a small size.
* DL architectures are bigger and bigger.
* A model can have 70 billion parameters.
* NVIDIA T4 GPUs have 16 GB RAM.
* Running models are still a challenge.
* The aim is to get a smaller model.
