---
layout: post
title: "quantization-1"
categories: medium
---

The notes in this article have been compiled from the lectures given in the references.

Why do we need quantization?

* Shrink models to a small size.
* DL architectures are bigger and bigger.
* A model can have 70 billion parameters.
* NVIDIA T4 GPUs have 16 GB RAM.
* Running models are still a challenge.
* The aim is to get a smaller model.

Clik here to read more: [link](https://medium.com/@balci.pelin/quantization-1-d05e5a61e0af)