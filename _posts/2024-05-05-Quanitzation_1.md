---
layout: post
title: "quantization-1"
categories: medium
---

[TL;DR? Read the full version on Medium](https://medium.com/@balci.pelin/quantization-1-d05e5a61e0af) Why do we need quantization?
* Shrink models to a small size.
* DL architectures are bigger and bigger.
* A model can have 70 billion parameters.
* NVIDIA T4 GPUs have 16 GB RAM.
* Running models are still a challenge.
* The aim is to get a smaller model.
