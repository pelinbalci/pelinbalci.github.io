---
layout: post
title: "LLM - Configurations"
categories: medium
---

[TL;DR? Read the full version on Medium](https://medium.com/@balci.pelin/llm-inference-222c8e8a6ba7) What are the configuration parameters that can influence the modelâ€™s output during 
inference? Click here to watch the video on [YouTube](https://youtu.be/KbUPOJ8Fmzs)